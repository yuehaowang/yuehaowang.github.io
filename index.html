<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css">
    <link href="/stylesheets.css" rel="stylesheet" >
    <title>Yuehao Wang</title>
  </head>
  <body>
    <div class="container">
        <main>
            <div id="info" class="row">
                <div class="col-4 avatar">
                    <img style="width: 100%;" src="/images/portrait.png" />
                    <p style="text-align: right; padding-top: 10px; padding-right: 5px; margin-bottom: 0px; font-size: 15px;">
                        <i class="bi-camera-fill" style="font-size: 1.0rem; padding-right: 1px;"></i> at <a href="https://goo.gl/maps/5YpCC8WKZkgdf4zs7">Sai Wan Beach</a> in 2022
                    </p>
                </div>
                <div class="col-8 contact">
                    <div class="d-flex justify-content-center">
                        <p>
                            <name>Yuehao Wang</name><br><br>
                            <span>
                                Master of Philosophy<br>
                                Dept. of Computer Science & Engineering<br>
                                The Chinese University of Hong Kong <br>
                                Sha Tin, New Territories, Hong Kong SAR
                            </span><br><br>
                            <span>
                                <i class="bi-envelope" style="font-size: 1.0rem; color: black; padding-right: 1px;"></i> yhwang [at] link.cuhk.edu.hk<br>
                                
                                [<a href="https://scholar.google.com/citations?user=WMAx_-gAAAAJ&hl=en" target="_blank">Scholar</a>]
                                <span style="margin-left: 4px;"></span>
                                [<a href="https://github.com/yuehaowang" target="_blank">Github</a>]
                                <span style="margin-left: 4px;"></span>
                                [<a href="https://www.linkedin.com/in/yuehaowang/" target="_blank">LinkedIn</a>]
                                <span style="margin-left: 4px;"></span>
                                [<a href="https://twitter.com/yuehaowang" target="_blank">Twitter</a>]
                            
                            </span>
                        </p>
                    </div>
                </div>
            </div>

            <hr>
            <div id="bio">
                I am a final year M.Phil. student at The Chinese University of Hong Kong.
                Before that, I obtained my bachelor's degree at ShanghaiTech University.
                Outside of academics, my hobbies include playing the (electric) guitar, creative coding, and designing video games
                (check out <a href="/showcase/">my showcase</a>).
            </div>
            <hr>

            <div class="section" id="research">
                <heading>Research</heading>

                <p class="mt-2 text-justify">
                    My topics of interest include computer graphics, 3D vision, computational photography, and their intersections with machine learning.
                    In particular, I work on projects in neural rendering and 3D reconstruction.
                    Below are my selected research publications. For the full list, please see <a href="https://scholar.google.com/citations?user=WMAx_-gAAAAJ&hl=en" target="_blank">here</a>.
                    <p class="mt-1">
                        <i>Note: * indicates authors with equal contribution.</i>
                    </p>
                </p>

                <!-- <ul class="nav nav-tabs" id="pubtabs" role="tablist">
                    <li class="nav-item" role="presentation">
                        <a href="#" class="nav-link active" id="home-tab" data-bs-toggle="tab" data-bs-target="selected" type="button" role="tab" aria-selected="true">Selected</a>
                    </li>
                    <li class="nav-item" role="presentation">
                        <a href="#" class="nav-link" id="profile-tab" data-bs-toggle="tab" data-bs-target="pub" type="button" role="tab" aria-selected="false">Full List</a>
                    </li>
                </ul> -->

                <div class="row item over-video selected pub">
                    <div class="col-3 thumbnail">
                        <div class="overlay-video">
                            <video width="100%" playsinline muted loop>
                                <source src="/images/paper_thumbnail/bilarf.mp4" type="video/mp4" />
                            </video>
                        </div>
                        <img width="100%" src="/images/paper_thumbnail/bilarf.jpg" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle>Bilateral Guided Radiance Field Processing</papertitle>
                        <span><u>Yuehao Wang</u>, <a href="https://github.com/1ss0dumb">Chaoyi Wang</a>, <a href="https://s2.hk/">Bingchen Gong</a>, <a href="https://tianfan.info/">Tianfan Xue</a></span>
                        <br>
                        <span><i>SIGGRAPH (ACM TOG), 2024</i></span>
                        <br>
                        <span>
                            We introduce 2D and 3D image signal processing (ISP) pipelines to NeRF for handling photometric variation and human-adjusted retouching.<br>
                            [<a href="https://arxiv.org/abs/2406.00448">Paper</a>] [<a href="https://github.com/yuehaowang/bilarf">Code</a>] [<a href="https://bilarfpro.github.io/">Webpage</a>]
                        </span>
                    </div>
                </div>

                <div class="row item over-video selected pub">
                    <div class="col-3 thumbnail">
                        <div class="overlay-video">
                            <video width="100%" playsinline muted loop>
                                <source src="/images/paper_thumbnail/seamlessnerf.mp4" type="video/mp4" />
                            </video>
                        </div>
                        <img width="100%" src="/images/paper_thumbnail/seamlessnerf.png" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle style="max-width: 550px; display: block;">SeamlessNeRF: Stitching Part NeRFs with Gradient Propagation</papertitle>
                        <span><a href="https://s2.hk/">Bingchen Gong</a>*, <u>Yuehao Wang</u>*, <a href="https://scholar.google.com/citations?user=z-rqsR4AAAAJ">Xiaoguang Han</a>, <a href="https://scholar.google.com/citations?user=iHh7IJQAAAAJ">Qi Dou</a></span>
                        <br>
                        <span><i>SIGGRAPH Asia, 2023</i></span>
                        <br>
                        <span>
                            We present a gradient-domain approach for seamless appearance blending of part NeRFs, drawing inspiration from Poisson image editing.
                            <br>
                            [<a href="https://Paper.org/abs/2311.16127">Paper</a>] [<a href="https://sites.google.com/view/seamlessnerf">Webpage</a>]
                        </span>
                    </div>
                </div>

                <div class="row item over-video selected pub">
                    <div class="col-3 thumbnail">
                        <div class="overlay-video">
                            <video width="100%" playsinline muted loop>
                                <source src="/images/paper_thumbnail/recolornerf.mp4" type="video/mp4" />
                            </video>
                        </div>
                        <img width="100%" src="/images/paper_thumbnail/recolornerf.png" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle style="max-width: 530px; display: block;">RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes</papertitle>
                        <span><a href="https://s2.hk/">Bingchen Gong</a>*, <u>Yuehao Wang</u>*, <a href="https://scholar.google.com/citations?user=z-rqsR4AAAAJ">Xiaoguang Han</a>, <a href="https://scholar.google.com/citations?user=iHh7IJQAAAAJ">Qi Dou</a></span>
                        <br>
                        <span><i>ACM MM, 2023</i></span>
                        <br>
                        <span>
                            We decompose NeRF into pure-color layers for palette-based color editing of 3D scenes.
                            <br>
                            [<a href="https://Paper.org/abs/2301.07958">Paper</a>] [<a href="https://github.com/yuehaowang/RecolorNeRF/">Code</a>] [<a href="https://sites.google.com/view/recolornerf">Webpage</a>]
                        </span>
                    </div>
                </div>
                
                <div class="row item over-video selected pub">
                    <div class="col-3 thumbnail">
                        <div class="overlay-video">
                            <video width="100%" playsinline muted loop>
                                <source src="/images/paper_thumbnail/nerf_surgery.mp4" type="video/mp4" />
                            </video>
                        </div>
                        <img width="100%" src="/images/paper_thumbnail/endonerf2.png" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle style="max-width: 550px; display: block;">Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery</papertitle>
                        <span><u>Yuehao Wang</u>, <a href="https://scholar.google.com/citations?user=HIjQdFQAAAAJ">Yonghao Long</a>, <a href="https://scholar.google.com/citations?user=YCMlfpAAAAAJ">Siu Hin Fan</a>, <a href="https://scholar.google.com/citations?user=iHh7IJQAAAAJ">Qi Dou</a></span>
                        <br>
                        <span><i>MICCAI, 2022</i> <b style="color: red;">(Oral Presentation, Student Travel Award, Young Scientist Award)</b></span>
                        <br>
                        <span>
                            A NeRF-based method for reconstructing deformable tissues from stereo endoscopic images.
                            <br>
                            [<a href="https://Paper.org/abs/2206.15255">Paper</a>] [<a href="https://github.com/med-air/EndoNeRF/">Code</a>] [<a href="https://med-air.github.io/EndoNeRF/">Webpage</a>]
                        </span>
                    </div>
                </div>

                <div class="row item over-video selected pub">
                    <div class="col-3 thumbnail">
                        <div class="overlay-video">
                            <video width="100%" playsinline muted loop>
                                <source src="/images/paper_thumbnail/nhr.mp4" type="video/mp4" />
                            </video>
                        </div>
                        <img width="100%" src="/images/paper_thumbnail/nhr.jpg" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle>Multi-View Neural Human Rendering</papertitle>
                        <span><a href="http://wuminye.com">Minye Wu</a>, <u>Yuehao Wang</u>, <a href="https://scholar.google.com/citations?user=kYHf73IAAAAJ">Qiang Hu</a>, <a href="http://www.yu-jingyi.com/">Jingyi Yu</a></span>
                        <br>
                        <span><i>CVPR, 2020</i></span>
                        <br>
                        <span>
                            We present an end-to-end Neural Human Renderer (NHR) for dynamic human captures under the multi-view setting.
                            <br>
                            [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Multi-View_Neural_Human_Rendering_CVPR_2020_paper.pdf">Paper</a>] [<a href="https://github.com/wuminye/NHR">Code</a>] [<a href="https://wuminye.github.io/NHR/">Webpage</a>]
                        </span>
                    </div>
                </div>
            </div>

            <div class="section" id="other_projects">
                <heading>Coding Projects</heading>
                
                <div class="row item mt-2">
                    <div class="col-3 thumbnail">
                        <img width="100%" src="/images/demo/volrend_flame.png" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle>Interactive Volume Renderer</papertitle>
                        <br>
                        <span>
                            An interactive volume visualizer for displaying implicit functions, medical data, smoke, etc., using CUDA for real-time rendering.
                            <br><br>
                            <a href="https://github.com/yuehaowang/volume_renderer" class="btn btn-sm btn-outline-primary" role="button" aria-pressed="true" target="_blank"><i class="bi bi-github pe-1"></i> View on Github</a>
                            <a href="https://drive.google.com/drive/folders/1H4_vyyNHNk-NSeIf7cve_XxySz47Aheg?usp=sharing" class="btn btn-sm btn-outline-primary" role="button" aria-pressed="true" target="_blank"><i class="bi bi-play-circle pe-1"></i> Videos</a>
                        </span>
                    </div>
                </div>

                <div class="row item">
                    <div class="col-3 thumbnail">
                        <img width="100%" src="/images/demo/lets_cg.png" />
                    </div>
                    <div class="col-9 abstract">
                        <papertitle>Let's Compute Graphics</papertitle>
                        <br>
                        <span>
                            A course project collection of graphics algorithms and applications, including OpenGL, global illumination,
                            Loop subdivision, etc.
                            <br><br>
                            <a href="https://github.com/yuehaowang/lets_CG" class="btn btn-sm btn-outline-primary" role="button" aria-pressed="true" target="_blank"><i class="bi bi-github pe-1"></i> View on Github</a>
                        </span>
                    </div>
                </div>
            </div>

            <div class="section" id="teaching">
                <heading>Teaching</heading>

                <div class="mt-3" style="padding-left: 5px;">
                    <div style="padding-left: 10px;">
                        <ul>
                            <li>Multimedia Coding and Processing - Fall 2023 @ CUHK (TA)</li>
                            <li>Fundamentals of Artificial Intelligence - Fall 2021, Fall 2022 @ CUHK (TA)</li>
                            <li>Introduction to Social Networks - Spring 2022 @ CUHK (TA)</li>
                            <li>Computer Graphics - Spring 2021 @ ShanghaiTech (TA)</li>
                            <li>Linear Algebra - Fall 2019, Fall 2020 @ ShanghaiTech (TA)</li>
                            <li>Introduction to Computer Programming - Fall 2018 @ ShanghaiTech (TA)</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="section" id="talks">
                <heading>Talks & Presentations</heading>

                <div class="mt-3" style="padding-left: 5px;">
                    <div style="padding-left: 10px;">
                        <ul>
                            <li>Invited talk at OpenRobotLab @ Shanghai AI Laboratory: <i>"Editable Representations for NeRF"</i>, Jan 2024.</li>
                            <li>Invited talk at Olympus ATR: <i>"3D Reconstruction of Deformable Soft Tissues via NeRF"</i>, Mar 2023.</li>
                            <li>Invited speaker at TUM: <i><a href="https://www.cs.cit.tum.de/camp/news/article/camp-learning-day-nerf-meets-medical-imaging/" target="_blank">"CAMP Learning Day: NeRF meets Medical Imaging"</a></i>, Oct 2022.</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div style="margin-top: 50px;"><hr></div>

            <footer class="text-end">
                <a style="padding-right: 5px;" href="https://www.easycounter.com/"><img src="https://www.easycounter.com/counter.php?yuehaowang" border="0" alt="Free Hit Counters"></a> unique visitors since Jul 2021.<br>
                &copy; 2024 Yuehao Wang. Last update: Jun 05, 2024.<br>
                <p style="font-size: small;">
                    The website template is adapted from <a href="https://jonbarron.info/">[1]</a> and <a href="https://richzhang.github.io/">[2]</a>.
                </p>
            </footer>
        </main>
    </div>

    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js" integrity="sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0" crossorigin="anonymous"></script>
    <script>
        function main() {
            overlay_video();
            pub_tabs();
            show_pub_by_classname('selected');
        }
        function overlay_video() {
            var nodes = document.querySelectorAll('.over-video');
            for(var i = 0; i < nodes.length; i++) {
                node = nodes[i]
                node.addEventListener('mouseenter', function(event) {
                    this.querySelector('.overlay-video').style.opacity = 1;
                    this.querySelector('video').currentTime = 0;
                    this.querySelector('video').play();
                });
                node.addEventListener('mouseleave', function(event) {
                    this.querySelector('.overlay-video').style.opacity = 0;
                    this.querySelector('video').pause();
                });
            }
        }
        function show_pub_by_classname(clsname) {
            // classnames: pub, selected, preprints
            const pub_entries = document.getElementsByClassName('pub');
            for (var i = 0; i < pub_entries.length; i++) {
                pub_el = pub_entries[i]
                if (pub_el.classList.contains(clsname)) {
                    pub_el.style.display = 'flex';
                } else {
                    pub_el.style.display = 'none';
                }
            }
        }
        function pub_tabs() {
            const triggerTabList = document.querySelectorAll('#pubtabs a');
            triggerTabList.forEach(triggerEl => {
                triggerEl.addEventListener('click', event => {
                    event.preventDefault();
                    show_pub_by_classname(triggerEl.dataset.bsTarget);
                });
            });
        }
        document.addEventListener('DOMContentLoaded', function() { main(); }, true);
    </script>
  </body>
</html>